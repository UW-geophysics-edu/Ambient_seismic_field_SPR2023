{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ee3ccaf",
   "metadata": {},
   "source": [
    "# Scatering Network for Seismology\n",
    "\n",
    "This notebook reproduces the tutorials from the SCATSEISNET package.\n",
    "\n",
    "the package is ultra minimal. I needed the following installation commands to make it work\n",
    "```bash\n",
    "conda create -n scatnetseis python=3.8 pip\n",
    "conda activate scatseisnet\n",
    "pip install matplotlib\n",
    "pip install scatnetseis\n",
    "pip install jupyter\n",
    "pip install obspy\n",
    "pip install -U scikit-learn\n",
    "python -m ipykernel install --user --name scatnetseis\n",
    "```\n",
    "After that you can start a jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f151e831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import numpy as np\n",
    "import obspy\n",
    "from obspy.clients.fdsn.client import Client \n",
    "import sklearn\n",
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "from scatseisnet import ScatteringNetwork\n",
    "%config InlineBackend.figure_format = \"svg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7067cf",
   "metadata": {},
   "source": [
    "### Scattering network parameters\n",
    "\n",
    "Copy pasted from the github:\n",
    "\n",
    "the number of octaves ( J, int) covered by the filter banks per layer. This defines the frequency range of analysis of the input data, from the Nyquist frequency fn down to fn/2^J , and should be decided according to the frequency range of interest for the task.\n",
    "\n",
    "the resolution ( Q, int) represents the number of wavelets for each octave, so the frequency resolution of the filterbank. This should be large for the first layer (dense) and small for the other layers (sparse), as indicated in And√©n and Mallat (2014).\n",
    "\n",
    "the quality factor (float) is the ratio between the center frequency of every wavelet and the bandwidth. Because we work with constant-Q filters, this is defined from the entire filter bank. The lower the quality factor, the more redundant the information in the scattering coefficients. We suggest using a quality factor 1 at the first layer, and a larger at the remaining layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d87dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_duration_seconds = 20.0\n",
    "sampling_rate_hertz = 50.0\n",
    "samples_per_segment = int(segment_duration_seconds * sampling_rate_hertz)\n",
    "# the network will have 2 layers\n",
    "bank_keyword_arguments = (\n",
    "    {\"octaves\": 4, \"resolution\": 4, \"quality\": 1},\n",
    "    {\"octaves\": 5, \"resolution\": 2, \"quality\": 3},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff509d87",
   "metadata": {},
   "source": [
    "### Create scatnet\n",
    "\n",
    "In the several papers on the topic, the authors have used the Gabor wavelet. In the packaged python script, they only offer the Morlet wavelet. We will try that out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973d03da",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = ScatteringNetwork(\n",
    "    *bank_keyword_arguments,\n",
    "    bins=samples_per_segment,\n",
    "    sampling_rate=sampling_rate_hertz,\n",
    ")\n",
    "\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfcd285",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath_save = \"./example\"\n",
    "\n",
    "# Create directory to save the results\n",
    "os.makedirs(dirpath_save, exist_ok=True)\n",
    "\n",
    "# Save the scattering network with Pickle\n",
    "filepath_save = os.path.join(dirpath_save, \"scattering_network.pickle\")\n",
    "with open(filepath_save, \"wb\") as file_save:\n",
    "    pickle.dump(network, file_save, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af85338e",
   "metadata": {},
   "source": [
    "Visualize the filter bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb50c045",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bank in network.banks:\n",
    "\n",
    "    # Create axes (left for temporal, right for spectral domain)\n",
    "    fig, ax = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "    # Show each wavelet\n",
    "    for wavelet, spectrum, ratio in zip(\n",
    "        bank.wavelets, bank.spectra, bank.ratios\n",
    "    ):\n",
    "\n",
    "        # Time domain\n",
    "        ax[0].plot(bank.times, wavelet.real + ratio, \"C0\")\n",
    "\n",
    "        # Spectral domain (log of amplitude)\n",
    "        ax[1].plot(bank.frequencies, np.log(np.abs(spectrum) + 1) + ratio, \"C0\")\n",
    "\n",
    "    # Limit view to three times the temporal width of largest wavelet\n",
    "    width_max = 3 * bank.widths.max()\n",
    "\n",
    "    # Labels\n",
    "    ax[0].set_ylabel(\"Octaves (base 2 log)\")\n",
    "    ax[0].set_xlabel(\"Time (seconds)\")\n",
    "    ax[0].set_xlim(-width_max, width_max)\n",
    "    ax[0].grid()\n",
    "    ax[1].set_xscale(\"log\")\n",
    "    ax[1].set_xlabel(\"Frequency (Hz)\")\n",
    "    ax[1].grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f04438b",
   "metadata": {},
   "source": [
    "Load seismograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ac06ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = Client(\"IRIS\")\n",
    "\n",
    "# Collect waveforms from the datacenter\n",
    "stream = client.get_waveforms(\n",
    "    network=\"YH\",\n",
    "    station=\"DC08\",\n",
    "    location=\"*\",\n",
    "    channel=\"*\",\n",
    "    starttime=obspy.UTCDateTime(\"2012-07-25T00:00\"),\n",
    "    endtime=obspy.UTCDateTime(\"2012-07-26T00:00\"),\n",
    ")\n",
    "\n",
    "stream.merge(method=1)\n",
    "stream.detrend(\"linear\")\n",
    "stream.filter(type=\"highpass\", freq=1.0)\n",
    "stream.plot(rasterized=True);\n",
    "\n",
    "stream.write(\"./example/scattering_stream.mseed\", format=\"MSEED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca6943f",
   "metadata": {},
   "source": [
    "Trim Seismograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015af0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract segment length (from any layer)\n",
    "segment_duration = network.bins / network.sampling_rate\n",
    "overlap = 0.5\n",
    "\n",
    "# Gather list for timestamps and segments\n",
    "timestamps = list()\n",
    "segments = list()\n",
    "\n",
    "# Collect data and timestamps\n",
    "for traces in stream.slide(segment_duration, segment_duration * overlap):\n",
    "    timestamps.append(mdates.num2date(traces[0].times(type=\"matplotlib\")[0]))\n",
    "    segments.append(np.array([trace.data[:-1] for trace in traces]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb803d0",
   "metadata": {},
   "source": [
    "### Scattering transform.\n",
    "Max pooling is prone to aliasing, so use reduce_type = mean as a method to pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdf354c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scattering_coefficients = network.transform(segments, reduce_type=np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52e650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the features in a pickle file\n",
    "np.savez(\n",
    "    \"./example/scattering_coefficients.npz\",\n",
    "    order_1=scattering_coefficients[0],\n",
    "    order_2=scattering_coefficients[1],\n",
    "    times=timestamps,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df43fa0e",
   "metadata": {},
   "source": [
    "observe the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f828d374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the first channel\n",
    "channel_id = 0\n",
    "trace = stream[channel_id]\n",
    "o_1 = np.log10(scattering_coefficients[0][:, channel_id, :].squeeze())\n",
    "center_frequencies = network.banks[0].centers\n",
    "\n",
    "# Create figure and axes\n",
    "fig, ax = plt.subplots(2, sharex=True, dpi=300)\n",
    "\n",
    "# Plot the waveform\n",
    "ax[0].plot(trace.times(\"matplotlib\"), trace.data, rasterized=True, lw=0.5)\n",
    "\n",
    "# First-order scattering coefficients\n",
    "ax[1].pcolormesh(timestamps, center_frequencies, o_1.T, rasterized=True)\n",
    "\n",
    "# Axes labels\n",
    "ax[1].set_yscale(\"log\")\n",
    "ax[0].set_ylabel(\"Counts\")\n",
    "ax[1].set_ylabel(\"Frequency (Hz)\")\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6410b427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from file\n",
    "with np.load(\"./example/scattering_coefficients.npz\", allow_pickle=True) as data:\n",
    "    order_1 = data[\"order_1\"]\n",
    "    order_2 = data[\"order_2\"]\n",
    "    times = data[\"times\"]\n",
    "# Reshape and stack scattering coefficients of all orders\n",
    "\n",
    "order_1 = order_1.reshape(order_1.shape[0], -1)\n",
    "order_2 = order_2.reshape(order_2.shape[0], -1)\n",
    "scattering_coefficients = np.hstack((order_1, order_2))\n",
    "\n",
    "# transform into log\n",
    "scattering_coefficients = np.log(scattering_coefficients)\n",
    "\n",
    "# print info about shape\n",
    "n_times, n_coeff = scattering_coefficients.shape\n",
    "print(\"Collected {} samples of {} dimensions each.\".format(n_times, n_coeff))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59b402e",
   "metadata": {},
   "source": [
    "## Dimensionality reduction\n",
    "\n",
    "This tutorial uses FastICA for the dimensionality reduction, but we can try other things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401facd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_latent = FastICA(n_components=5, whiten=\"unit-variance\", random_state=42)\n",
    "features = model_latent.fit_transform(scattering_coefficients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d0914d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the features\n",
    "np.savez(\n",
    "    \"./example/independent_components.npz\",\n",
    "    features=features,\n",
    "    times=times,\n",
    ")\n",
    "\n",
    "# Save the dimension reduction model\n",
    "with open(\"./example/dimension_model.pickle\", \"wb\") as pickle_file:\n",
    "    pickle.dump(\n",
    "        model_latent,\n",
    "        pickle_file,\n",
    "        protocol=pickle.HIGHEST_PROTOCOL,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ffed84",
   "metadata": {},
   "source": [
    "Plots the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9712b40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features for display\n",
    "features_normalized = features / np.abs(features).max(axis=0)\n",
    "\n",
    "# Figure instance\n",
    "fig = plt.figure(dpi=200)\n",
    "ax = plt.axes()\n",
    "\n",
    "# Plot features\n",
    "ax.plot(times, features_normalized + np.arange(features.shape[1]), rasterized=True)\n",
    "\n",
    "# Labels\n",
    "ax.set_ylabel(\"Feature index\")\n",
    "ax.set_xlabel(\"Date and time\")\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7685d454",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d04a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a feature\n",
    "feature_id = 0\n",
    "feature = features[:, feature_id]\n",
    "\n",
    "# Figure creation\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "\n",
    "# Plot the weights\n",
    "ax.plot(times, feature)\n",
    "ax.set_ylabel(f\"Amplitude of feature {feature_id}\")\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3654d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract weights from the dimensionality reduction model\n",
    "feature_id = 1\n",
    "weights = model_latent.components_[feature_id]\n",
    "vmax = np.abs(weights).max()/4\n",
    "\n",
    "# Scattering coefficients shape and frequencies\n",
    "n_cha = 3\n",
    "n_order_1 = network.banks[0].octaves * network.banks[0].resolution\n",
    "n_order_2 = network.banks[1].octaves * network.banks[1].resolution\n",
    "f_1 = network.banks[0].centers\n",
    "f_2 = network.banks[1].centers\n",
    "\n",
    "# Extract and reshape weights\n",
    "order_1 = weights[: n_cha * n_order_1].reshape(n_cha, n_order_1)\n",
    "order_2 = weights[n_cha * n_order_1 :].reshape(n_cha, n_order_1, n_order_2)\n",
    "\n",
    "# Show weights\n",
    "fig, ax = plt.subplots(nrows=2, ncols=3, sharex=True, sharey=\"row\")\n",
    "image_kw = dict(vmin=-vmax, vmax=vmax, rasterized=True, cmap=\"PuOr\")\n",
    "for id, channel in enumerate(\"BHZ\"):\n",
    "\n",
    "    # Show\n",
    "    ax[0, id].plot(f_1, order_1[id], label=channel)\n",
    "    mappable = ax[1, id].pcolormesh(f_1, f_2, order_2[id].T, **image_kw)\n",
    "\n",
    "    # Labels\n",
    "    ax[0, id].set_title(channel)\n",
    "    ax[1, id].set_xlabel(\"$f_1$ (Hz)\")\n",
    "\n",
    "# Labels\n",
    "ax[0, 0].set_ylabel(\"Unmixing weights\")\n",
    "ax[1, 0].set_ylabel(\"$f_2$ (Hz)\")\n",
    "ax[1, 0].set_xscale(\"log\")\n",
    "ax[1, 0].set_yscale(\"log\")\n",
    "\n",
    "# Colorbar\n",
    "colorbar = fig.colorbar(mappable, orientation=\"horizontal\", ax=ax, shrink=0.3)\n",
    "colorbar.set_label(\"Unmixing weights\")\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b81286",
   "metadata": {},
   "source": [
    "Reconstruction\n",
    "\n",
    "We here reconstruct the scattering coefficients from a selected independent components. We only show the first order coefficients, since the second order coefficients are hard to map as a function of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c19e358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out latent space\n",
    "features_filtered = np.zeros(features.shape)\n",
    "features_filtered[:, feature_id] = feature\n",
    "\n",
    "# Extract all scattering coefficients\n",
    "reconstructed = model_latent.inverse_transform(features_filtered)\n",
    "reconstructed_order_1 = reconstructed[:, : n_cha * n_order_1].reshape(-1, n_cha, n_order_1)\n",
    "vmin = reconstructed_order_1.min()\n",
    "vmax = reconstructed_order_1.max()\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(nrows=3, sharex=True, sharey=\"row\")\n",
    "\n",
    "# Plot\n",
    "for id, channel in enumerate(\"BHZ\"):\n",
    "    data = reconstructed_order_1[:, id, :].squeeze().T\n",
    "    mappable = ax[id].pcolormesh(times, f_1, data, rasterized=True, vmin=vmin, vmax=vmax)\n",
    "    ax[id].set_ylabel(\"$f_1$ (Hz)\")\n",
    "    ax[id].set_yscale(\"log\")\n",
    "\n",
    "# Colorbar\n",
    "colorbar = fig.colorbar(mappable, orientation=\"vertical\", ax=ax, shrink=0.5)\n",
    "colorbar.set_label(\"Scattering coefficients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f694330",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "We will use Kmeans here. Reload the models to make things fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5908dbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a67ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features and datetimes from file\n",
    "with np.load(\"./example/independent_components.npz\", allow_pickle=True) as data:\n",
    "    features = data[\"features\"]\n",
    "    times = data[\"times\"]\n",
    "\n",
    "# Load network\n",
    "network = pickle.load(open(\"./example/scattering_network.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8a2eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLUSTERS = 15\n",
    "\n",
    "# Perform clustering\n",
    "model_cluster = KMeans(n_clusters=N_CLUSTERS, n_init=\"auto\", random_state=4)\n",
    "model_cluster.fit(features)\n",
    "\n",
    "# Predict cluster for each sample\n",
    "predictions = model_cluster.predict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b9f4c2",
   "metadata": {},
   "source": [
    "Vizualize cluster-wise detection rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f867c115",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMOOTH_KERNEL = 20\n",
    "\n",
    "# Convert predictions to one-hot encoding\n",
    "one_hot = np.zeros((len(times), N_CLUSTERS + 1))\n",
    "one_hot[np.arange(len(times)), predictions] = 1\n",
    "\n",
    "# Plot the results\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "# Plot each cluster as a separate line\n",
    "for i in range(N_CLUSTERS):\n",
    "\n",
    "    # Obtain the detection rate by convolving with a boxcar kernel\n",
    "    detection_rate = np.convolve(one_hot[:, i], np.ones(SMOOTH_KERNEL), mode=\"same\") / SMOOTH_KERNEL\n",
    "\n",
    "    # Plot the detection rate\n",
    "    ax.plot(times, one_hot[:, i] + i, alpha=0.5)\n",
    "    ax.plot(times, detection_rate + i, color=\"black\")\n",
    "\n",
    "# Labels\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.set_ylabel(\"Cluster index\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b29224",
   "metadata": {},
   "source": [
    "Get cluster coordinates in the feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85635764",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = np.abs(model_cluster.cluster_centers_)\n",
    "\n",
    "# Plot the centroids\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "\n",
    "# Show the centroids as a heatmap\n",
    "mappable = ax.matshow(centroids.T, cmap=\"RdPu\")\n",
    "\n",
    "# Labels\n",
    "plt.colorbar(mappable).set_label(\"Amplitude\")\n",
    "ax.set_xlabel(\"Cluster index\")\n",
    "ax.set_ylabel(\"Feature index\")\n",
    "\n",
    "# Ticks below\n",
    "ax.xaxis.set_ticks_position(\"bottom\")\n",
    "ax.set_xticks(np.arange(N_CLUSTERS))\n",
    "ax.set_yticks(np.arange(centroids.shape[1]))\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d65325",
   "metadata": {},
   "source": [
    "Now display the waveforms that we clustered in each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5657ee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_WAVEFORMS = 5\n",
    "\n",
    "# Read the stream\n",
    "stream = obspy.read(\"./example/scattering_stream.mseed\").select(channel=\"BHN\")\n",
    "waveform_duration = network.bins / network.sampling_rate\n",
    "\n",
    "# Extract waveforms\n",
    "waveforms = list()\n",
    "for cluster in np.unique(predictions):\n",
    "\n",
    "    # Calculate the distance of each sample to the cluster mean\n",
    "    mean = np.mean(features[predictions == cluster], axis=0)\n",
    "    distance = np.linalg.norm(features[predictions == cluster] - mean, axis=1)\n",
    "    closest = times[predictions == cluster][distance.argsort()[:5]]\n",
    "\n",
    "    # Collect closest waveforms in a list\n",
    "    traces = list()\n",
    "    for time in closest[:N_WAVEFORMS]:\n",
    "        time = obspy.UTCDateTime(time)\n",
    "        trace = stream.slice(time, time + waveform_duration)[0].copy()\n",
    "        traces.append(trace)\n",
    "    waveforms.append(traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8283de",
   "metadata": {},
   "source": [
    "Now plot the waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e67877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "fig, ax = plt.subplots(N_WAVEFORMS, N_CLUSTERS, sharex=True, sharey=True, dpi=300)\n",
    "\n",
    "# Plot each cluster as a separate line\n",
    "for i, traces in enumerate(waveforms):\n",
    "    ax[0, i].set_title(f\"Cluster {i}\", rotation=\"vertical\")\n",
    "    for j, trace in enumerate(traces):\n",
    "        ax[j, i].plot(trace.times(), trace.data, rasterized=True, lw=0.6, color=f\"C{i}\")\n",
    "        ax[j, i].set_axis_off()\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3a8b9c",
   "metadata": {},
   "source": [
    "In this tutorial, we failed at detecting the onset of the landslides. We can repeat the analysis by playing with the following parameters:\n",
    "* number of clusters\n",
    "* numbers of ICAs\n",
    "* the original data\n",
    "* the clustering algorithm, you may choose agglomerative clustering\n",
    "* Depth of the scattering network. Someone could help in creating a class with Gabor wavelets."
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "scatnetseis",
   "language": "python",
   "name": "scatnetseis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
